Введение.
Интеллектуальный анализ данных (Data Mining) в настоящее время является активно развивающейся областью (написать что-нибудь про перспективы развития этой области). 
В данной работе была предпринята попытка использования методов Data Mining для работы (?) с электронной англоязычной энциклопедией Википедия.
(Написать, почему Википедия)
  Data mining - процесс выделения полезных закономерностей  (useful patterns) в больших массивах данных.
Data Mining тесно связан с такими областями науки, как искусственный интеллект и математическая статистика.
Когда в качестве данных выступает текст, то можно говорить о такой разновидности  Data Mining, как Text Mining.
Text mining - процесс выделения полезных закономерностей (useful patterns) в больших массивах текста на естественном языке. Text mining = Text Data Mining.

Существуют следующие основные направления Data mining:
1. классификация;
2. кластеризация;
3. извлечение правил ассоциаций;
4. выборка атрибутов.
Приведённые направления носят в основном эвристическую природу.
Классификация
d -> l, D contains d, P contains p.
где D - исходное множество документов, L – множество классов документов. В отличие от кластеризации, множество классов задано изначально.
Предполагается наличие обучающего набора образцов документов, для которого доступна информация о принадлежности к классам.
Кластеризация 
d -> p, P contains p, D contains d
где D - исходное множество документов, P – множество выделенных кластеров.
Документы разделяются на кластеры таким образом, что:
•	внутри одного кластера документы однородны;
•	 документы из разных кластеров разнородны.
Объекты и атрибуты 
Для развитых алгоритмов данные об объекте хранятся в виде фиксированного списка атрибутов. Множество объектов составляет базу данных (БД). Приведём пример подобной базы данных:
•	множество объектов _ множество видов животных;
•	вариант множества атрибутов: вид (str),средний вес (float), кормление молоком (bool),наличие шерсти (bool), длина названия вида (int).
Извлечение правил ассоциаций
Извлечение правил ассоциаций заключается в поиске интересных и полезных закономерностей в БД.
Пример: выберем два атрибута: средний вес и наличие шерсти, можем получить следующее логическое выражение: если средний вес равен 50 кг, и есть шерсть, то вид - волк или шимпанзе, и т. д.
Выборка атрибутов
Выборка атрибутов - задача сортировки атрибутов объектов по их информационной содержательности.
Пример: в БД после работы алгоритма выборки атрибутов должны получить список: вид, средний вес, кормление молоком, наличие шерсти. Здесь нет атрибута “длина названия
вида”, т.к. он, очевидно, не несет никакой информационной ценности.
(Рассказать про изученность первых двух направлений. Рассказать, что заниматься буду последними двумя)
Основная часть.
Один из возможных способов работы с Википедией  представлен в статье Wikipedia mining for an association web thesaurus construction [7]. Авторы предлагают алгоритм создания тезауруса (словаря, отражающего «похожесть» между словами), в основе которого лежит использование таких показателей, как количество путей между двумя статьями, длины этих путей, а так же количество входящих ссылок отдельно взятой статьи. Последний показатель указывает, является ли текущая статья general term. Если величина этого показателя сравнительно велика, то перед нами general term.
Для подсчета количества путей используется степень матрицы смежности графа, построенного на основании наличия ссылки между двумя соответствующими статьями. Так как размерность такой матрицы велика, но сама матрица при этом разрежена, для ее хранения и выполнение операции умножения используется n бинарных деревьев (свое для каждой строки).
Как правило, тезаурус включает в себя несколько типов семантик, из которых две являются базовыми: синонимы и антонимы. Предположительно, синонимы можно найти, используя связи между статьями, но проблема нахождения антонимов в статье не обсуждается. Без идеи о нахождении антонимов этот подход не является полезным. (переформулировать?)
Проект Weka.
Weka - это свободно распространяемый пакет для анализа данных, написанный на языке Java в университете Уайкато (Новая Зеландия).
Weka позволяет выполнять такие важные задачи анализа данных, как извлечение правил ассоциаций и выборка атрибутов. В качестве источника данных могут использоваться реляционные БД или структурированные данные в формате CSV.
(рассказать про упоминание в Google, ссылка)
В ходе более подробного изучения выяснилось, что алгоритмы Weka не пригодны для наших целей: они не рассчитаны на работу с большим количеством атрибутов. Помимо этого, алгоритмы являются эвристическими, так что всерьез на них рассчитывать не стоит.


 
