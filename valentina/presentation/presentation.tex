\documentclass{beamer}

\usepackage[russian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{cmap}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{psfrag}
\usepackage{amsfonts}
%%\usepackage{amssymb}

\newcommand{\MARK}[1]{{\bf {\it #1}}}
\newcommand{\CODE}[1]{{\ttfamily #1}}

\setbeamertemplate{footline}[frame number]
\usecolortheme{seahorse}
\beamertemplateshadingbackground{white}{blue!3}

\begin{document}
\begin{frame}
\begin{center}
Кирюшкина Валентина \\
\vspace{1cm}
{\Large Исследование алгоритмов извлечения знаний с~использованием\\ 
материалов свободной энциклопедии Wikipedia}\\ 
\end{center}
\end{frame}

\begin{frame}
\frametitle{Data mining и Text Mining}
Data mining --- процесс нахождения полезных закономерностей (useful patterns)  в~большом наборе данных.\\
\vspace{1cm}
Text mining --- процесс выделения полезных закономерностей (useful patterns) 
в~больших массивах текста на~естественном языке. 
Text mining = Text Data Mining.
\end{frame}

\begin{frame}
\frametitle{Задача извлечения знаний из Wikipedia}
Основная задача --- научиться извлекать как можно больше знаний на~основе Wikipedia,
которые могут быть использованы  при~создании различных прикладных интеллектуальных утилит.
Важные свойства Wikipedia:

\begin{enumerate}

\item {Одна статья --- одно понятие (сущность).}
\item{Предоставляет материалы по именам собственным.}

\end{enumerate}

Обработка имён собственных в~тексте может проводиться только при~наличии базы данных.

\end{frame}

\begin{frame}
\frametitle{Достоинства Wikipedia}

Важные особенности:
\begin{itemize}
\item{большое число статей;}
\item{регулярные обновления для~поддержания актуальности;}
\item{большое количество ссылок между статьями.}
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Основные направления Text Mining}
\begin{enumerate}
\item{Классификация.}
\item{Кластеризация.}
\item{Извлечение информации (эвристические алгоритмы поиска закономерностей).}
\item{Построение графа знаний в~виде семантической сети.}

\end{enumerate}
\end{frame}

\begin{frame}
\frametitle{Классификация документов}
$$D \mapsto L, L \in \mathbb{L},$$
\vspace{1cm}
где $\mathbb{L}$ --- множество категорий документов.\\
\vspace{1cm}
В~отличие от~кластеризации множество категорий задано изначально.
\vspace{1cm}
Заранее задаётся обучающий набор образцов документов, для которых известна их~принадлежность к~классам.
\end{frame}

\begin{frame}
\frametitle{Кластеризация документов}
$$D \mapsto P, P \in \mathbb{P},$$
\vspace{1cm}
где $\mathbb{P}$ --- множество кластеров.\\
\vspace{1cm}
Документы разделяются на~подмножества таким образом, что:

\begin{itemize}
\item{внутри одного подмножества документы \underline{однородны};}
\item{документы из разных подмножеств \underline{разнородны}.}
\end{itemize}
\vspace{1cm}
$Dist(d_{1},d_{2})$ --- мера расстояния между документами.
\end{frame}

\begin {frame}
\frametitle{Построение тезауруса}
Задача: Построение тезауруса - словаря, отражающего семантические отношения
между словами, в данном случае --- близость между словами.\\
\vspace{1cm}
Входной материал: Множество статей, которые рассматриваются как понятия.\\
\vspace{1cm}
Выходной материал: значение функции, аргументами которой являются две~статьи, 
соответствующие понятиям, степень близости между которыми необходимо установить.
\end{frame}

\begin{frame}
\frametitle{Алгоритм построения тезауруса}
Поскольку Wikipedia состоит из множества статей (понятий) и гиперссылок между ними, она может быть представлена
в виде графа $G = \{V,E\}$, где $V$  --- это множество статей, а $E$ ---это множество ссылок.\\
Близость между понятиями(статьями) $v_i$ и $v_j$ зависит от~следующих параметров:

\vspace{1cm}

\begin{itemize}
\item{количества путей между $v_i$ и $v_j$;}
\item{длины каждого пути между $v_i$ и $v_j$;}
\item{количество входящих ссылок.}
\end{itemize}

\vspace{1cm}
Путь между двумя статьями --- это последовательность ссылок (их~количество определяет длину пути), которая соединяет данные статьи.\\

\end{frame}

\begin{frame}
\frametitle{Извлечение информации}
Задача извлечения информации заключается в получении структурированных знаний
из~текста на~естественном языке.\\

\vspace{1cm}
Подзадачи:
\begin{enumerate}
\item{Распознавание именованных сущностей.}
\item{Извлечение информации из~слабоструктурированных текстов.}
\item{Нахождение терминологии, специфичной для данного документа..}
\end{enumerate}

\vspace{1cm}

Данные могут быть представлены в~виде объектов с атрибутами.

\vspace{1cm}
{\bf Пример.} Дано предложение на~естественном языке: 
``Robert L. James, chairman and chief executive
officer of McCann-Erickson, is going to retire on July 1st. He will be replaced
by John J.Donner, Jr., the agencies chief operating officer.''
Получим следующие атрибуты: организация (McCann-Erickson), должность (chief executive officer),
дата(July 1), имя уходящего с должности человека (Robert L. James), имя
приходящего на должность человека (John J. Donner, Jr.).

\end{frame}

\begin{frame}
\frametitle{Weka (Waikato Environment for Knowledge Analysis)}
Weka --- свободно распространяемый пакет для анализа данных,
написанный на языке Java в университете Уайкато (Новая Зеландия). \\

\vspace{1cm}
Группы алгоритмов Weka:
\begin{itemize}
\item{классификация;}
\item{кластеризация;}
\item{задача выборки атрибутов;}
\item{Задача извлечения правил ассоциаций.}
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Объекты и атрибуты}
Нередко данные  об объекте хранятся в виде фиксированного списка атрибутов.\\
\vspace{1cm}
Опишем базу данных, которую будем использовать на следующих слайдах в~качестве примера.\\
\vspace{1cm}
Возьмем в качестве рассматриваемых объектов разных животных.
Список атрибутов будет следующим:
вид(строка), средний вес(число), кормление молоком(булевый), наличие шерсти(булевый), длина названия вида(число).
\end{frame}

\begin{frame}
\frametitle{Извлечение правил ассоциаций}
Основной задачей является поиск интересных и полезных закономерностей в базе данных.\\
\vspace{1cm}
\bf{Пример.}
Выберем два атрибута: средний вес и наличие шерсти.
Можем получить следующее логическое выражение: 
если средний вес = 50 кг и шерсть = 1  $\to$ вид = волк или вид = шимпанзе.
И так далее.

\end{frame}

\begin{frame}
\frametitle{Выборка атрибутов}
Задача сортировки атрибутов объектов по~их~информационной содержательности.\\
\vspace{1cm}
\bf{Пример.}
\vspace{1cm}
В нашей базе данных в результате действия алгоритмов выборки атрибутов получим отсортированный список: вид, средний вес, кормление молоком, наличие шерсти.\\
Очевидно, что атрибут «длина названия вида» не несет никакой информационной ценности.
\end{frame}

\begin{frame}
\frametitle{Критика идеи построения тезауруса и проекта Weka}

Сложности при работе с Weka:
\begin{enumerate}
\item{Необходимость построения базы знаний  с объектами и атрибутами: на~данном этапе качественно почти невозможно.}
\item{Большое число атрибутов для~обработки: вычислительно трудоёмко.}
\end{enumerate}

Алгоритм построения тезауруса основан на классификации и кластеризации.
Сами по себе алгоритмы классификации и кластеризации являются эвристическими с~крайне ограниченным потенциалом для~будущих исследований.

\end{frame}

\begin{frame}
\frametitle{Граф знаний}
Граф знаний есть ориентированный(в большинстве случаев) граф, в котором вершины представляют так называемые концепты (токены и типы),
а ребра --- отношения между ними.
Причем отношения могут быть как бинарные, так и многомерные.\\ 

\textsl{Токену} соответствует какой-либо реальный объект или абстрактное понятие.
 На графе он обозначается как $\Box$. \\

Токен, отражающий некоторое общее понятие, в терминологии графа знаний называется \textsl{типом}.\\
\end{frame}

\end{document}
